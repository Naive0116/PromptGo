#!/usr/bin/env python3
"""
æ›´æ–° _all_documents.jsonï¼Œæ·»åŠ æ–°çˆ¬å–çš„è¯­æ–™åº“æ–‡æ¡£
"""
import json
from pathlib import Path


def load_corpus_file(filepath: Path) -> list:
    """ä»å•ä¸ªè¯­æ–™åº“æ–‡ä»¶åŠ è½½æ–‡æ¡£å—"""
    with open(filepath, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    documents = []
    chunks = data.get("chunks", [])
    
    for i, chunk in enumerate(chunks):
        doc = {
            "doc_id": f"{data['id']}_chunk_{i}",
            "content": chunk,
            "metadata": {
                "source_id": data["id"],
                "source_type": data.get("type", "guide"),
                "source_url": data.get("url", ""),
                "priority": data.get("priority", "P1"),
                "topic": data.get("topic", "prompting"),
                "tags": ",".join(data.get("tags", [])),
                "notes": data.get("notes", ""),
                "chunk_index": i,
                "total_chunks": len(chunks),
                "type": "corpus_knowledge"
            }
        }
        documents.append(doc)
    
    return documents


def update_all_documents():
    """æ›´æ–° _all_documents.json"""
    cache_dir = Path(__file__).parent.parent / "data" / "corpus_cache"
    all_docs_file = cache_dir / "_all_documents.json"
    
    # åŠ è½½ç°æœ‰æ–‡æ¡£
    if all_docs_file.exists():
        with open(all_docs_file, "r", encoding="utf-8") as f:
            existing_docs = json.load(f)
        print(f"å·²åŠ è½½ {len(existing_docs)} ä¸ªç°æœ‰æ–‡æ¡£")
    else:
        existing_docs = []
        print("æœªæ‰¾åˆ°ç°æœ‰æ–‡æ¡£ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
    
    # è·å–ç°æœ‰æ–‡æ¡£çš„ source_id é›†åˆ
    existing_source_ids = set()
    for doc in existing_docs:
        source_id = doc.get("metadata", {}).get("source_id", "")
        existing_source_ids.add(source_id)
    
    # æ–°å¢çš„è¯­æ–™åº“æ–‡ä»¶
    new_corpus_files = [
        "OPENAI_GPT5_PROMPTING_GUIDE.json",
        "OPENAI_GPT41_PROMPTING_GUIDE.json",
        "OPENAI_PROMPT_PERSONALITIES.json",
        "OPENAI_CUSTOMER_SERVICE_EXAMPLE.json",
        "OPENAI_REALTIME_PROMPTING_GUIDE.json",
    ]
    
    new_docs = []
    for filename in new_corpus_files:
        filepath = cache_dir / filename
        if filepath.exists():
            source_id = filename.replace(".json", "")
            if source_id not in existing_source_ids:
                docs = load_corpus_file(filepath)
                new_docs.extend(docs)
                print(f"âœ… æ·»åŠ  {filename}: {len(docs)} ä¸ªæ–‡æ¡£å—")
            else:
                print(f"â­ï¸ è·³è¿‡ {filename}: å·²å­˜åœ¨")
        else:
            print(f"âŒ æœªæ‰¾åˆ° {filename}")
    
    # åˆå¹¶æ–‡æ¡£
    all_docs = existing_docs + new_docs
    
    # ä¿å­˜
    with open(all_docs_file, "w", encoding="utf-8") as f:
        json.dump(all_docs, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“Š æ›´æ–°å®Œæˆï¼")
    print(f"   åŸæœ‰æ–‡æ¡£: {len(existing_docs)}")
    print(f"   æ–°å¢æ–‡æ¡£: {len(new_docs)}")
    print(f"   æ€»è®¡æ–‡æ¡£: {len(all_docs)}")


if __name__ == "__main__":
    update_all_documents()
